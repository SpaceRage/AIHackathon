<!doctype html>
<html class="no-js" lang="">

<head>
  <meta charset="utf-8">
  <title> Responsible AI Hackathon: Spotcheck </title>
  <meta name="description" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:title" content="">
  <meta property="og:type" content="">
  <meta property="og:url" content="">
  <meta property="og:image" content="">

  <link rel="manifest" href="site.webmanifest">
  <link rel="apple-touch-icon" href="icon.png">
  <!-- Place favicon.ico in the root directory -->

  <link rel="stylesheet" href="css/normalize.css">
  <link rel="stylesheet" href="css/main.css">

  <meta name="theme-color" content="#fafafa">

</head>

<body>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/request/2.88.2/index.min.js"></script>
  <script src="main.js"></script>
  <!-- The navigation bar at the top of the page -->

  <nav class="navbar">
    <ul class="nav-list">
      <li><a href="#">Model</a></li>
      <li><a href="#background-scroll">Background</a></li>
      <li><a href="#about-scroll">About Us</a></li>
    </ul>
  </nav>

  <br><br>

  <div>

    <div class="bodydiv">

    <div class="section" id="model-form">

      <h1> Responsible AI Hackathon: SpotCheck </h1>

      <h2 class="model-heading"> Model </h2>

      <!-- The panel with the model -->
      <div id="input-form">
        <form action="main.js">

          <div class="flex-container">
            <div class="image-upload">
              <label for="image_upload" id="custom_image_upload">
                Browse
              </label>
              <input accept="image/*" type="file" id="image_upload" name="filename">
              <img id="user_preview" src="img/transparent-pic.png" alt="[Image Preview]">
            </div>

            <!-- The other information the user needs to upload, which is age, gender and localization-->
            <div id="gender-age">

              <!-- Gender -->
              <div id="gender">
                <label for="gender-male"> Male </label>
                <input type="radio" name="gender-choice" value="choice-1">
                <label for="gender-female"> Female </label>
                <input type="radio" name="gender-choice" value="choice-2">
              </div>

              <!-- Age -->
              <div id="age">
                <label for="age"> Age: </label>
                <input type="number" min="0" name="age-input">
              </div>
              
              <!-- Localization -->
              <div id="localization">
                <label for="localization"> Localization: </label>
                <select name="localization" id="location-select">
                  <option value="unknown">Unknown</option>
                  <option value="lower-ex">Lower Extremity</option>
                  <option value="upper-ex">Upper Extremity</option>
                  <option value="torso">Torso</option>
                  <option value="head-neck">Head/Neck</option>
                  <option value="palm-sole">Palm/Sole</option>
                  <option value="oral-genital">Oral/Genital</option>
                  <option value="hands-feet">Oral/Genital</option>
                </select>
              </div>

            </div>
          </div>

          <br>

          <label for="image_submit" id="custom_image_submit">Upload</label>
          <input type="submit">
        </form>
      </div>
    </div>

    <!-- Background -->
    <div id="background-scroll"></div>

    <div class="section" id="background">
      <h2> Background </h2>
      <p>

        As atmospheric UVA and UVB radiation levels have risen over the past decades due to global warming, the risk of skin cancer and its related complications has risen alongside it [4]. With this increased risk, more patients have become curious about whether their skin lesions may be benign or indicative of melanoma or carcinoma. This, paired with the growing popularity of telehealth, has drawn many of these patients to perform check-ups online, and this opened the market for image-processing-based applications. These apps provide pseudo diagnoses for cancerous lesions, and although they claim levels of success upwards of 90% accuracy in detecting malignant lesions [3], meta-analyses show rates of even 30% are optimistic [7]. This discrepancy is only amplified by the fact that many of these applications, which are trained based on physician diagnoses [3].

      </p>
    </div>

    <div class="section" id="background">
      <h2> Model Data </h2>
        <p>
        The data that many modern applications train on use American-made image datasets such as the HAM10000, which contain zoomed color images of various skin lesions. Albeit these datasets are often specific in terms of metadata, they are also largely unrepresentative across the range of human skin tones, even with the consideration that skin lesions are more common in those with light skin. This leads to inherent bias in the applications which decreases the accuracy of diagnoses in dark-skinned patients, similar to the implicit bias in many physicians who are often trained on primarily light-skinned patients and have more difficulty recognizing malignancy in dark-skinned lesions [6].
        <br> <br>
        Our model aims to remove a large component of this bias by training it on a more representative and inclusive dataset, provided by the International Skin Imaging Collaboration (ISIC) [2] and merged with a portion of the HAM10000 set. Images with metadata containing an unknown diagnosis were removed, and the resulting dataset was converted to greyscale and preprocessed before training the model.
        </p>
    </div>

    <div class="section" id="background">
      <h2> Modeling Method </h2>
        <p>
          The model is built using the Keras API with TensorFlow as the backend. It takes as input images of size 224x224 pixels, along with the patient's age, sex, and the location of the skin lesion.
          The ResNet50 architecture is used as the base model for lesion extraction. The base model is frozen so that only the fully connected layers are trained during the training process and speeding up the process. The fully connected layers include age, sex, and localization as inputs to the model, which are combined with the extracted features from the base model. The model's architecture is optimized using the Keras Tuner API, which searches for the optimal set of hyperparameters such as the number of layers, number of units per layer, learning rate, dropout rate, etc. The model is trained using binary cross-entropy loss and optimized using the Adam optimizer. The accuracy of the model is evaluated using the test dataset. Finally, the trained model is saved for later use in the final website.          
        </p>
    </div>

    <div class="flex-container">
      <div class="section" id="model">
        <br>
        <h2> Data Normalization </h2>
        <p>
          To identify the mark on differing skin types and colors, the image processing script first isolates and blurs out any hair to remove noise. Then, the image is converted to grayscale, and the distribution of black/white levels in the image is equalized to make the skin levels in each image the same, thus the baseline for identifying the mark is the same for each. Finally, the mark is isolated using contour identification, and a mask is applied to the image to isolate the mark and take out any external noise/marks.
          <br> <br>
          During processing, the script attempts to resize the dataset images such that they are all of similar sizes to facilitate masking and dataset consistency. However, this can sometimes result in the loss of resolution during processing, which results in visually blurrier images.
          <br> <br>
          <br> <br>
        </p>
      </div>
      <div class="section">
        <h4> Image Processing </h4>
        <div class="flex-container" id="image-row1" >
          <img src="img/darkskintest.png" height="200" width="200">
          <img src="img/darkskintestchanged.png" height="200" width="200">
        </div>
        <div class="flex-container" id="image-row2">
          <img src="img/lightskintest.jpg" height="200" width="200">
          <img src="img/lightskinchanged.jpg" height="200" width="200">
        </div>
          <article> 
            Image normalization done prior to training.
            <br>
            Left: Unprocessed image
            Right: Normalized image
          </article>
      </div>
      
    </div>

    <div id="about-scroll"></div>

    <div class="section" id="about">
      <h2> About Us </h2>

      <div class="flex-container" id="rajiv-intro">
        <div>
          <h3> Rajiv Iyer </h3>
          <p>
            Hi! I’m Rajiv, currently studying Computer Science and Business Administration. In this project, I worked primarily on the website, the bridge backend/API between the site and model, and the image processing script for masking/filtering our dataset as well as inputted images. Through this project, I have improved my knowledge in areas like OpenCV, TensorFlow, web development, and crafting APIs.
          </p>
        </div>
        <img id="rajiv-photo" src="img/rajiv.jpeg" height="250" width="210">
      </div>

      <div class="flex-container" id="luisa-intro">
        <div>
          <h3> Luisa Li </h3>
          <p>
            Hello! I’m Luisa, studying Computer Science and Mathematics. For this project, I mostly focused on the website itself and working with HTML files and CSS stylesheets, brainstorming the information that we want to show and designing the look and feel of our website. I also dabbled with a bit of OpenCV and image processing. I believe that AI ethics is the single most important AI research field as of now, as emerging technologies and methods for responsible deployment impacts us all. This project intrigued me specifically for its emphasis on fairness, and I’m glad I was able to learn and grow along with my team. 
          </p>
        </div>
        <img id="luisa-photo" src="img/luisa.jpeg" height="300" width="250">
      </div>

      <div class="flex-container" id="adam-intro">
        <div>
          <h3> Adam Hakansson </h3>
          <p>
            Hey! I’m Adam, currently studying bioengineering, and I worked primarily on the background research for this project as well as the data analysis. I’ve gained a background in biological research and MATLAB, and when we came upon literature covering the discrepancies between melanoma cases and prognosis by race, it was the exact type of project we wanted to work on to increase equity in medical diagnoses.
          </p>
        </div>
        <img id="adam-photo" src="img/adam.png" height="250" width="200">
      </div>

      <div class="flex-container" id="mad-intro">
        <div>
          <h3> Madhav Kapa </h3>
          <p>
            Hi! I’m Madhav, currently studying Computer Science and Physics. In this project, I have worked on building and tweaking the model. In the initial stages, I did initial research on our feasible ideas, and looked for datasets that we could use for training. During the remaining phase of the project, I wrote the script for training and built the model itself using Python, TensorFlor and Keras. 
          </p>
        </div>
        <img id="mad-photo" src="img/mad.png" height="250" width="250">
      </div>
      
    </div>

    <div class="section">
      <h3> Works Cited </h3>
      <p>
        [1] Davis, Lauren E et al. “Current state of melanoma diagnosis and treatment.” Cancer biology & therapy vol. 20,11 (2019): 1366-1379. doi:10.1080/15384047.2019.1640032
        <br>
        [2] Isic Challenge, challenge.isic-archive.com/.
        <br>
        [3] Jain, Satin et al. “Deep Learning-Based Transfer Learning for Classification of Skin Cancer.” Sensors (Basel, Switzerland) vol. 21,23 8142. 6 Dec. 2021, doi:10.3390/s21238142
        <br>
        [4] “Melanoma Incidence and Mortality, United States–2012–2016.” Centers for Disease Control and Prevention, Centers for Disease Control and Prevention, 27 June 2019, www.cdc.gov/cancer/uscs/about/data-briefs/no9-melanoma-incidence-mortality-UnitedStates-2012-2016.htm.
        <br>
        [5] “Melanoma: Symptoms, Stages, Diagnosis, Treatment & Prevention.” Cleveland Clinic, my.clevelandclinic.org/health/diseases/14391-melanoma.
        <br>
        [6] Ward-Peterson, Melissa et al. “Association Between Race/Ethnicity and Survival of Melanoma Patients in the United States Over 3 Decades: A Secondary Analysis of SEER Data.” Medicine vol. 95,17 (2016): e3315. doi:10.1097/MD.0000000000003315
        <br>
        [7] Wolf, Joel A et al. “Diagnostic inaccuracy of smartphone applications for melanoma detection.” JAMA dermatology vol. 149,4 (2013): 422-6. doi:10.1001/jamadermatol.2013.2382
      </p>
    </div>

    <script src="js/vendor/modernizr-3.11.2.min.js"></script>
    <script src="js/plugins.js"></script>
    <script src="js/main.js"></script>

    <!-- Google Analytics: change UA-XXXXX-Y to be your site's ID. -->
    <script>
      window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
      ga('create', 'UA-XXXXX-Y', 'auto'); ga('set', 'anonymizeIp', true); ga('set', 'transport', 'beacon'); ga('send', 'pageview')
    </script>
    <script src="https://www.google-analytics.com/analytics.js" async></script>
</body>

</div>

<footer>
  <!-- Legal disclaimer-->
  <div>
    </div>br>
    <label for="disclaimer">
      Disclaimer: This tool is not for clinical use, the results of this model do not constitute a clinical diagnosis
      <br>
      Consult a medical professional for true concerns.
    </label>
  </div>
</footer>

</html>